---
title: "Final Product"
author: "Palma"
date: "11/30/2021"
output: html_document
---

```{r, error=FALSE}
library(nflfastR)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggrepel)
library(stringr)
library(lubridate)
library(tidymodels)        # for modeling
library(themis)            # for step functions for unbalanced data
library(doParallel)        # for parallel processing
library(stacks)            # for stacking models
library(naniar)            # for examining missing values (NAs)
library(moderndive)        # for King County housing data
library(vip)               # for variable importance plots
library(patchwork)         # for combining plots nicely
library(ranger)
library(readr)
library(ggimage)
library(xgboost)
library(kableExtra)
library(expss)
library(knitr)
library(skimr)
library(baguette) 
library(future)
```

```{r}
pbp_2018_2021 <- load_pbp(2018:2021)
nfl_qbr_weekly <- readr::read_csv("https://raw.githubusercontent.com/nflverse/espnscrapeR-data/master/data/qbr-nfl-weekly.csv")
nfl_qbr_weekly<-nfl_qbr_weekly %>% 
  filter(season==2018:2021)
```

# Intro to the "Two Minute Drill"

Show win probability .... what happens here that changes the outcome?

Show QB face plots

Show most successful plots

What will we be modeling / looking into?

# Intro Visualizations 

3 - 4 intro visualizations investigating interesting behavior....

specifically ones that directly have impications upon the outcome (score?)

```{r}
Two_min_drill <- pbp_2018_2021 %>% 
  filter(half_seconds_remaining<120, as.numeric(ms(drive_game_clock_start))<150) 
  
Two_min_drill %>% 
  group_by(game_id, drive) %>%
  select(game_id, drive_play_count, ydsnet, drive_game_clock_start, fixed_drive_result, name, posteam, week, drive_start_yard_line, wp) %>%
  mutate(td = ifelse(fixed_drive_result=='Touchdown', 1, 0),
  fg = ifelse(fixed_drive_result=='Field goal', 1, 0)) %>%
  mutate(score= ifelse(td+fg==1, 1,0))

```

```{r}
Two_min_drill

Two_min_drill %>% 
  group_by(game_id, drive) %>%
  mutate(rush_attempt = ifelse(is.na(rush_attempt), 0, rush_attempt)) %>% 
  mutate(pass_attempt = ifelse(is.na(pass_attempt), 0, pass_attempt)) %>%
  summarize(num_plays= n(), num_rush=sum(rush_attempt), num_pass= sum(pass_attempt))
  
```

```{r}
two_min_new <- Two_min_drill %>% 
  group_by(game_id, drive) %>%
  mutate(td = ifelse(fixed_drive_result=='Touchdown', 1, 0),
  fg = ifelse(fixed_drive_result=='Field goal', 1, 0), 
  score= ifelse(td+fg==1, 1,0)) %>%
  right_join(nfl_qbr_weekly, by = c("week" = "game_week", "posteam"="team_abb", "season" = "season")) %>% 
  ungroup()
```


```{r}
two_min_new %>%
  select(passer, ydsnet, qbr_total, qbr_raw, game_id.x, headshot_href)
```

```{r}
two_min_by_drive <- 
  two_min_new  %>%
    group_by(drive, game_id.x) %>%
    mutate(run_plays = sum(rush_attempt, na.rm = TRUE), 
           pass_plays = sum(pass_attempt, na.rm = TRUE), 
           pass_tot_yds = sum(air_yards, na.rm = TRUE), 
           completion_perc = (1- sum(incomplete_pass, na.rm = TRUE) / pass_plays), 
           tot_yds = sum(yards_gained, na.rm = TRUE),
           rush_yds_tot = sum(rushing_yards, na.rm = TRUE)) %>% 
     mutate(td = ifelse(fixed_drive_result=='Touchdown', 1, 0),
            fg = ifelse(fixed_drive_result=='Field goal', 1, 0), 
            score = ifelse(td+fg==1, 1,0)) %>%
    select(passer, qbr_raw, qbr_total, pass_tot_yds, tot_yds, ydsnet, rush_yds_tot, rusher, completion_perc, run_plays, pass_plays, drive_yards_penalized, tot_yds, drive_game_clock_start, td, fg, score, posteam, drive_start_yard_line, headshot_href, wp, season) %>% 
  mutate(yards_to_go_start= ifelse(str_extract(drive_start_yard_line, "[A-Z]+")== posteam, 100- parse_number(drive_start_yard_line), parse_number(drive_start_yard_line))) 
```

```{r}
drive_summary_data <- two_min_by_drive %>%
 arrange(game_id.x, drive) %>% 
 group_by(game_id.x) %>% 
  mutate(
    td = as.factor(td), 
    fg = as.factor(fg), 
    score = as.factor(score)
  ) %>%
 summarise_all(last)

drive_summary_data <- drive_summary_data %>% 
  mutate(passer= replace(passer, passer=="Aa.Rodgers", "A.Rodgers"))

drive_summary_data
```
```{r}
drive_summary_data %>% 
  summarize(num_td_drives= sum(td==1), num_fg_drives= sum(fg==1), num_drives=n(), td_success_perc= num_td_drives/num_drives, fg_success_perc= num_fg_drives/num_drives)
```

```{r}
drive_summary_data %>% 
  group_by(season) %>%
  summarize(season, num_td_drives= sum(td==1), num_fg_drives= sum(fg==1), num_drives=n(), td_success_perc= num_td_drives/num_drives, fg_success_perc= num_fg_drives/num_drives ) %>% 
  dplyr::slice(1) %>% 
  dplyr::rename("Number of TD's Scored"= num_td_drives) %>%
  dplyr::rename("Number of FG's Scored"= num_fg_drives) %>%
  dplyr::rename("Number of Drives"= num_drives) %>%
  dplyr::rename("TD Success Rate"= td_success_perc) %>%
  dplyr::rename("FG Success Rate"= fg_success_perc) %>%
  kbl() %>% 
  kable_paper("striped") %>% 
  add_header_above(c("2-minute Drills in the last 4 Seasons" = 6))  
```


```{r}
drive_summary_data %>%
  group_by(passer) %>% 
  summarize(num_successful= sum(score==1), num_2min_drives= n(), success_perc= num_successful/num_2min_drives, headshot=headshot_href) %>%
  arrange(desc(num_successful)) %>%  
  dplyr::slice(1) %>% 
  ggplot(aes(x=num_2min_drives, y= num_successful))+
  geom_text_repel(aes(label=passer)) +
  geom_image(aes(image= headshot), size=0.05, asp= 16/9)+
  labs(x= "Number of 2-minute drill drives",
       y= "Number of Successfull 2-minute drill drives",
       title= "Every QB 2-Minute Drill Efficiency from 2018-2021",
       caption = "Data: @nflfastR")+
  scale_y_continuous(breaks = scales::pretty_breaks(n = 8)) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 15))+
  theme_bw()
```

```{r}
drive_summary_data %>%
  ggplot(aes(x=qbr_total, y=wp, color=score))+ 
  geom_point()+
  labs(x="Total QBR for that week",
       y= "Current Winning Percentage during the Drive",
       title = "Does scoring(TD or FG) on a 2-Minute Drill Drive increase Win Percentage?",
       caption = "Data: @nflfastR",
       color= "Scored?")+
  scale_color_manual(labels = c("No", "Yes"), values = c("blue", "red"))
  
```



# Modeling 


```{r}
two_min_test <- 
  two_min_new  %>%
    group_by(drive, game_id.x) %>%
    mutate(run_plays = sum(rush_attempt, na.rm = TRUE), 
           pass_plays = sum(pass_attempt, na.rm = TRUE), 
           pass_tot_yds = sum(air_yards, na.rm = TRUE), 
           completion_perc = (1- sum(incomplete_pass, na.rm = TRUE) / pass_plays), 
           tot_yds = sum(yards_gained, na.rm = TRUE),
           rush_yds_tot = sum(rushing_yards, na.rm = TRUE)) %>% 
     mutate(td = ifelse(fixed_drive_result=='Touchdown', 1, 0),
            fg = ifelse(fixed_drive_result=='Field goal', 1, 0), 
            score = ifelse(td+fg==1, 1,0)) %>%
    select(qbr_raw, qbr_total, pass_tot_yds, tot_yds, ydsnet, rush_yds_tot, completion_perc, run_plays, pass_plays, drive_yards_penalized, tot_yds, drive_game_clock_start, td, fg, score, posteam, drive_start_yard_line)
```


```{r}
two_min_by_drive <-
  two_min_test %>%
    mutate(yards_to_go_start= ifelse(str_extract(drive_start_yard_line, "[A-Z]+")== posteam, 100- parse_number(drive_start_yard_line), parse_number(drive_start_yard_line))) 
  

two_min_by_drive
```

```{r}
drive_summary_data <- two_min_by_drive %>%
 arrange(game_id.x, drive) %>% 
 group_by(game_id.x) %>% 
  mutate(
    td = as.factor(td), 
    fg = as.factor(fg), 
    score = as.factor(score),
    drive_game_clock_start = as.numeric(ms(drive_game_clock_start))
    ) %>%
 summarise_all(last)

drive_summary_data
```

```{r}
drive_summary_data$yards_to_go_start[is.na(drive_summary_data$yards_to_go_start)] <- 50

```


```{r}
drive_summary_data %>%
  select(game_id.x, drive_game_clock_start, completion_perc, yards_to_go_start)
```

1. Logistic Regression with Lasso


# Lasso Logisitic Regression 

```{r}
library(dplyr)       # for data manipulation (dplyr) 
library(broom)       # for making model summary tidy
library(visreg)      # for plotting logodds and probability 
library(margins)     # to calculate Average Marginal Effects
library(ROCR)  
```

```{r}
drive_summary_data$completion_perc[is.na(drive_summary_data$completion_perc)] <- 0

```

```{r}
drive_summary_data$ydsnet[is.na(drive_summary_data$ydsnet)] <- 0
drive_summary_data$drive_yards_penalized[is.na(drive_summary_data$drive_yards_penalized)] <- 0
drive_summary_data$drive_game_clock_start[is.na(drive_summary_data$drive_game_clock_start)] <- 0
drive_summary_data$score[is.na(drive_summary_data$score)] <- 0

```


```{r}
drive_summary_data <- 
  drive_summary_data %>%
  select( -posteam, -td, -fg, -game_id.x, -drive, -drive_start_yard_line)

```


```{r}
drive_summary_data %>% 
  add_n_miss() %>% 
  count(n_miss_all)
```


```{r}

set.seed(2)

drive_two_min_split <- initial_split(drive_summary_data, 
                             prop = .75, strata = score)

drive_two_min_training <- training(drive_two_min_split)
drive_two_min_testing <- testing(drive_two_min_split)


```


3. Set up the recipe and the pre-processing steps to build a lasso model


```{r}
drive_two_min_training %>% 
  add_n_miss() %>% 
  count(n_miss_all)
```
```{r}
drive_two_min_training %>%
count(score)
```



```{r}
set.seed(2)

lasso_recipe <- recipe(score ~ ., 
                       data = drive_two_min_training) %>% 
  step_upsample(score, over_ratio = 1) %>%
  step_dummy(all_nominal(), 
             -all_outcomes()) %>%
  step_normalize(all_predictors(), 
                 -all_outcomes())

```


```{r}
lasso_recipe %>% 
  prep(drive_two_min_training) %>%
  juice() 
```


# Lasso Model and WF

```{r}
lasso_mod  <- 
  logistic_reg(mixture = 1) %>% 
  set_engine("glmnet") %>% 
  set_args(penalty = tune()) %>% 
  set_mode("classification")

lasso_wf <-  workflow() %>% 
  add_recipe(lasso_recipe) %>% 
  add_model(lasso_mod)

lasso_wf
```

# More Lasso Set up

```{r}

set.seed(2) 
cv_split <- vfold_cv(drive_two_min_training, 
                              v = 5)



penalty_grid <- grid_regular(penalty(),
                             levels = 10)

penalty_grid
```

```{r}

lasso_tune <-  
  lasso_wf %>% 
  tune_grid(
    resamples = cv_split,
    grid = penalty_grid,
    control = control_stack_grid())




```

```{r}

lasso_tune %>% 
  select(id, .metrics) %>% 
  unnest(.metrics) %>% 
  filter(.metric == "accuracy")


```


```{r}
lasso_tune %>% 
  collect_metrics() %>% 
  filter(.metric == "accuracy") %>% 
  ggplot(aes(x = penalty, y = mean)) +
  geom_point() +
  geom_line() +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10",scales::math_format(10^.x))) +
  labs(x = "penalty", y = "accuracy")
```


```{r}
lasso_tune %>% 
  show_best(metric = "accuracy")
```

```{r}
best_param <- lasso_tune %>% 
  select_best(metric = "accuracy")
best_param
```


```{r}
best_param <- lasso_tune %>%
  select_best(metric = "accuracy")

best_param
```


```{r}
lasso_final_wf <- lasso_wf %>% 
  finalize_workflow(best_param)
lasso_final_wf
```



```{r}
lasso_final_mod <- lasso_final_wf %>% 
  fit(data = drive_two_min_training)

lasso_final_mod %>% 
  pull_workflow_fit() %>% 
  tidy() 
```


```{r}
lasso_final_mod %>% 
  pull_workflow_fit() %>% 
  vip()
```


```{r}
lasso_test <- lasso_final_wf %>% 
  last_fit(drive_two_min_split)

lasso_test %>% 
  collect_metrics()
```

```{r}
collect_predictions(lasso_test) 

```


```{r}
preds <-
  collect_predictions(lasso_test) 
conf_mat(preds, .pred_class, score)
```


```{r}
accuracy(preds, truth = score,
         estimate = .pred_class)
```

```{r}
sens(preds, truth = score,
         estimate = .pred_class)
```

**Ratio between how much classified as score to how much was actually a score**

```{r}
spec(preds, truth = score,
         estimate = .pred_class)
```
**Ratio between how much classified as no score to how much was actually no score**

```{r}
precision(preds, truth = score,
         estimate = .pred_class)
```
**How much were correctly classified as a score out of all scores?**


```{r}
f_meas(preds, truth = score,
         estimate = .pred_class)
```
**The F1 score is about 0.818, which indicates that the trained model has a classification strength of 81.8%%.**


```{r}
custom_metrics <- metric_set(accuracy, sens, spec, precision, f_meas)

custom_metrics(preds, truth = score,
         estimate = .pred_class)
```


```{r}
roc_auc(preds,
        truth = score,
        .pred_0)
```

**ROC-AUC is a performance measurement for the classification problem at various thresholds settings. ROC_AUC tells how much the model is capable of distinguishing between classes. The trained logistic regression model has a ROC-AUC of ______**

```{r}
preds %>%
  roc_curve(truth = score, .pred_0) %>%
  autoplot()
```


```{r}
preds %>%
  ggplot() +
  geom_density(aes(x = .pred_0, fill = score), 
               alpha = 0.5)
```


```{r}
drive_two_min_training
```

```{r}
new_qb <- tribble(~qbr_raw, ~qbr_total, ~pass_tot_yds, ~tot_yds, ~ydsnet, ~rush_yds_tot, ~completion_perc, ~run_plays, ~pass_plays, ~drive_yards_penalized, ~drive_game_clock_start, ~yards_to_go_start,
                     70, 75, 50, 70, 80, 20, 0.6, 4, 7, 20, 115, 90)
new_qb
```

```{r}
predict(lasso_final_mod, new_data = new_qb)

```


2. Decision Tree -- Random Forest

```{r}

set.seed(2)

drive_two_min_split <- initial_split(drive_summary_data, 
                             prop = .75, strata = score)

drive_two_min_training <- training(drive_two_min_split)
drive_two_min_testing <- testing(drive_two_min_split)

cv_split <- vfold_cv(drive_two_min_training, 
                              v = 5)
```


```{r}
rf_recipe <- recipe(score ~ ., 
                       data = drive_two_min_training) %>% 
  step_upsample(score, over_ratio = 1) 
```


```{r}
set.seed(2)
rf_model <- rand_forest(mtry = tune(), 
              min_n = tune(), 
              trees = 100) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")
```

```{r}
rf_workflow <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_model) 
```



```{r}
rf_penalty_grid <- grid_regular(
  finalize(mtry(), drive_two_min_training %>% select(-score)),
  min_n(),
  levels = 3)


rf_tune <- 
  rf_workflow %>% 
  tune_grid(
    resamples = cv_split, 
    grid = rf_penalty_grid, 
    control = control_stack_grid())
```

```{r}
rf_tune %>%
  select_best(metric = "accuracy")
```
```{r}
rf_tune %>%
  collect_metrics(metric = "accuracy") %>%
  filter(.config == "Preprocessor1_Model1")
```



3.  Boosted Decision Tree

```{r}
xgboost_spec <-
  boost_tree(
    trees = 1000,
    min_n = 5,
    tree_depth = 2,
    learn_rate = tune(),
    loss_reduction = 10^-5,
    sample_size = 1) %>%
  set_mode("classification") %>%
  set_engine("xgboost")

xgboost_recipe <- recipe(formula = score ~ ., data = drive_two_min_training) %>%
  step_upsample(score, over_ratio = 1) %>%
  step_mutate_at(all_numeric(),
                 fn = ~as.numeric(.)) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_zv(all_predictors())

xgboost_workflow <-
  workflow() %>%
  add_recipe(xgboost_recipe) %>%
  add_model(xgboost_spec)

set.seed(2)
registerDoParallel() 

boost_penalty_grid <- grid_regular(
  learn_rate(),
  levels = 10)

boost_tune <- xgboost_workflow %>% 
    tune_grid(
    resamples = cv_split, 
    grid = boost_penalty_grid, 
    control = control_stack_grid())
```


```{r}
boost_tune %>%
  select_best(metric = "accuracy")
```

```{r}
boost_tune %>%
  collect_metrics(metric = "accuracy") %>%
  filter(.config == "Preprocessor1_Model10")
```

# Comparison

```{r}
lasso_tune %>% 
  collect_predictions() %>% 
  group_by(id, penalty) %>% 
  summarize(accuracy = sum((score == .pred_class))/n(),
            true_neg_rate = sum(score == 0 & .pred_class == 0)/sum(score == 0),
            true_pos_rate = sum(score == 1 & .pred_class == 1)/sum(score == 1)) %>% 
  group_by(penalty) %>% 
  summarize(across(accuracy:true_pos_rate, mean))
```

```{r}
rf_tune %>% 
  collect_predictions() %>% 
  group_by(id, mtry, min_n) %>% 
  summarize(accuracy = sum((score == .pred_class))/n(),
            true_neg_rate = sum(score == 0 & .pred_class == 0)/sum(score == 0),
            true_pos_rate = sum(score == 1 & .pred_class == 1)/sum(score == 1)) %>% 
  group_by(mtry, min_n) %>% 
  summarize(across(accuracy:true_pos_rate, mean))
```

```{r}
boost_tune %>% 
  collect_predictions() %>% 
  group_by(id, learn_rate) %>% 
  summarize(accuracy = sum((score == .pred_class))/n(),
            true_neg_rate = sum(score == 0 & .pred_class == 0)/sum(score == 0),
            true_pos_rate = sum(score == 1 & .pred_class == 1)/sum(score == 1)) %>% 
  group_by(learn_rate) %>% 
  summarize(across(accuracy:true_pos_rate, mean))
```




# Conclusion 

<<<<<<< HEAD

=======
What did we uncover about two min drills?

When are they more successful? When are they less? What vars are the most important?
>>>>>>> df2a57f636984d74ab99d9deb37f4ec34c26f7a7
