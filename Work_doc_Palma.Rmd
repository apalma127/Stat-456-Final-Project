---
title: "Work Doc - Palma"
author: "Palma"
date: "11/16/2021"
output: html_document
---


For the projects, I want to give some suggested due dates:

Friday 11/19: 1. Create a GitHub project and add collaborators (I'll go through an example of this on Tuesday). 2. At least 1 data source obtained,  data read in to R, basic visualizations/summarizations to verify data is as expected. Start doing some data cleaning. 3. Outline of analysis plan with some of the steps completed.

Tuesday 11/23: 1. Read in and clean other two sources of data. 2. Finish a couple of the analysis steps and write them up completely. I recommend focusing on the "final product" first. 3. Create an RMarkdown file for the "behind-the-scenes" report and be sure to keep track of any detailed explanations of methods and code there. 

Thursday 12/2: 1. Complete most of the analyses and have a draft of the "final product". 2. Begin creating a presentation. 3. Create a detailed outline of what will go in the "behind-the-scenes". 

Tuesday 12/7: 1. "Final product" complete. 2. Finish the 15 minute presentation and practice it with your group. 

Thursday 12/9: 1. Submit "final product" on moodle. 2. Give presentations - we may need to use a bit of the lunch hour. 

Thursday 12/16: Submit "behind-the-scenes" (you can always submit early, if you'd like). 


```{r}
library(nflfastR)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggrepel)
library(stringr)
library(lubridate)

library(tidymodels)        # for modeling
library(themis)            # for step functions for unbalanced data
library(doParallel)        # for parallel processing
library(stacks)            # for stacking models
library(naniar)            # for examining missing values (NAs)
library(moderndive)        # for King County housing data
library(vip)               # for variable importance plots
library(patchwork)         # for combining plots nicely
library(ranger)
library(xgboost)
pbp_2021 <- load_pbp(2021)
```


```{r}
#devtools::install_github(repo = "ryurko/nflscrapR")
```


```{r}
library(nflscrapR)

```


```{r}
two_min_drill <- pbp_2021 %>% 
  filter(half_seconds_remaining<120, as.numeric(ms(drive_game_clock_start))<150) 
  
two_min_new <- two_min_drill %>% 
  group_by(game_id, drive) %>%
  mutate(td = ifelse(fixed_drive_result=='Touchdown', 1, 0),
  fg = ifelse(fixed_drive_result=='Field goal', 1, 0), 
  score= ifelse(td+fg==1, 1,0)) %>%
  ungroup()

```


```{r}
two_min_by_drive <- 
  two_min_drill %>%
    group_by(drive, game_id) %>%
    mutate(run_plays = sum(rush_attempt, na.rm = TRUE), 
           pass_plays = sum(pass_attempt, na.rm = TRUE), 
           pass_tot_yds = sum(air_yards, na.rm = TRUE), 
           completion_perc = (1- sum(incomplete_pass, na.rm = TRUE) / pass_plays), 
           penalties = sum(penalty, na.rm = TRUE)) %>%
    select(run_plays, pass_plays, rush_attempt, pass_attempt, pass_tot_yds, completion_perc, penalties, drive_yards_penalized, yards_gained)
```


```{r}
two_min_by_drive
```


```{r}
two_min_new
```

```{r}
two_min_final <- 
  two_min_new %>%
  mutate(game_id = as.factor(game_id), 
         drive_game_clock_start = as.factor(drive_game_clock_start), 
         fixed_drive_result = as.factor(fixed_drive_result))
```

```{r}
two_min_final
```

```{r}
count<-apply(two_min_final, 2, function(col) sum(is.na(col))/length(col))
dims<-dim(two_min_final)
num<-dims[1]*dims[2]
NApercentage<-(count/num) 
print(NApercentage)

```



```{r}
two_min_final %>%
  count(game_id)
```

```{r}
two_min_final %>%
  count(drive)
```

```{r}
two_min_final %>%
  count(drive_play_count)
```

```{r}
two_min_final %>%
  count(ydsnet)
```

```{r}
two_min_final %>%
  count(drive_game_clock_start)
```

```{r}
two_min_final %>%
  count(fixed_drive_result)
```


```{r}
two_min_final %>%
  count(td)
```

```{r}
two_min_final %>%
  count(fg)
```


```{r}
two_min_final %>%
  count(score)
```

1.  Exploring Data


**Quant Vars**

```{r}
two_min_final %>% 
  select(where(is.numeric)) %>% 
  pivot_longer(cols = everything(),
               names_to = "variable", 
               values_to = "value") %>% 
  ggplot(aes(x = value)) +
  geom_histogram(bins = 30) +
  facet_wrap(vars(variable), 
             scales = "free", 
            nrow = 25)

```

**Categorical**

```{r}
two_min_final %>%
select(where(is.factor)) %>% 
  pivot_longer(cols = everything(),
               names_to = "variable", 
               values_to = "value") %>% 
  ggplot(aes(x = value)) +
  geom_bar() +
  facet_wrap(vars(variable), 
             scales = "free", 
             nrow = 3)
```

2.  Training / Testing 


```{r}
set.seed(2)

two_min_split <- initial_split(two_min_drill, 
                             prop = .75, strata = "score")

two_min_training <- training(two_min_split)
two_min_testing <- testing(two_min_split)
```


3. Set up the recipe and the pre-processing steps to build a lasso model

```{r}
set.seed(2)

lasso_recipe <- recipe(score ~ ., 
                       data = two_min_training) %>% 
  # step_upsample(score, over_ratio = 0.5) %>%
  # step_downsample(score, under_ratio = 1) %>%
  step_mutate_at(all_numeric(), 
                fn = ~ as.numeric(.)) %>%
  step_dummy(all_nominal(), 
             -all_outcomes()) %>% 
  step_normalize(all_predictors(), 
                 -all_nominal())
```


```{r}
lasso_recipe %>% 
  prep(two_min_training) %>%
  juice() 
```




